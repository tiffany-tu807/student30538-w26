---
title: "Dashboards"
author: "Peter Ganong and Maggie Shi"
date: today
date-format: long
format:
    revealjs:
        code-overflow: scroll
execute: 
    echo: true
slide-number: c/t
---


# Introduction


<!--
## Table of contents

::: {.toc}

:::-->

## Skills acquired by end of lecture 
* Understand benefits (and drawbacks) of dashboards 
* Launch `streamlit` dashboards locally and deploy online
* Make basic static and interactive dashboards
* Set up dashboards that run efficiently

## Materials for this lecture {style="font-size: 0.9em"}
* We will review code for several example dashboards
* `all_snippets.pdf`: all code reviewed in lecture
* Full source code for example dashboards stored in a separate repo than student repo: [https://github.com/uchicago-harris-dap/dashboards](https://github.com/uchicago-harris-dap/dashboards). 
    * Clone to access source code and launch apps locally
    * When lecture material says `1/hello_world_1.py`, `2/hello_world_2_local.py`, we are referencing this repo
    * Example dashboards are also deployed online and linked


## From A Static Process
![](pictures/process_1.png){ width=70% fig-align="center"}

::: {.notes}
* Review table of contents (does not render as a separate slide)
* When you submit a problem set or read a paper, It usually is imagined to follow a process like this
* Number one you write the code 
* number two you run the code
* number three the recipient looks like at output. 
:::

## To A Dynamic Process
![](pictures/process_2.png){ width=70% fig-align="center"}

::: {.notes}
* Except that  for anyone who has spent time at the Harris School or in another research environment, you know that this is not actually anything like how research happens. 
* In practice after you look at the output, you interact with the output and then you go back and you change the code and you run the code again and you look at the output again. 
:::

## To A Dynamic Process
![](pictures/process_2.png){ width=70% fig-align="center"}

When you analyze a dataset, your process looks a lot more like the dynamic one than the static one. 


::: {.notes}

:::


## To A Dynamic Process
![](pictures/process_3.png){ width=70% fig-align="center"}


Dashboards allow someone who does not code to do a limited version of the same process you go through as you code.

::: {.notes}
What dashboards to do is they enable someone who does not write code to do a small scale version of the skill that you already have, which is to manipulate the code and re-examine the output.
:::

## To A Dynamic Process
![](pictures/process_4.png){ width=70% fig-align="center"}


::: {.notes}
The other thing dashboard is that they need your code to be run not just on your computer but also run on a personal web server. 
:::

## Other benefits of dashboards 

* There are two other major benefits of dashboards which we will not spend time on in class, but you should also know about 
    * Consolidated information: aggregate data from various sources into one unified interface
    * Real-time data metrics: dynamic view based on automatically-updated data feed 
* *(Third benefit is that they are impressive: they are a great way to flex your data skills for your portfolio!)*

## Where we are going

[http://uchicago-harris-dap-dashboards-4.streamlit.app/](http://uchicago-harris-dap-dashboards-4.streamlit.app/)


::: {.notes}
Poke around here a bit to clarify that this is what we will be able to do by the end of the lecture note

Points to highlight:
* There is an underlying dataset that the user does not see that is generating all of these graphics
* Discussion question: what are the variables in this dataset?
    * hour of pickup
    * minute of pickup
    * number of pickup
    * Some kind of geography 
* There must be code that generates the maps as well as the graph
* Slider to select hour of pickup: equivalent to subsetting this dataset by hour of pickup
* When user selects a value in the slider, in the background the dataset is being subsetted to another hour, and the maps and graphs are being re-generated based on that subset.
* Side note: 3D graphs :( we are using this because this is a classic streamlit example
:::

## Dashboards: Promises and Pitfalls

When Professor Ganong worked in the Mayor's Office in Boston, the mayor asked for every single department to suggest metrics for a dashboard. The mayor put a TV in his office so that the dashboards would be displayed at all times.

**Discussion questions**: 

1. What are examples of data that a city would benefit from tracking with a dashboard?
2. What are examples of data where putting it on a dashboard might inadvertently lead to poor management or create bad incentives for workers?


::: {.notes}

1.
Clearance rate for reported crimes,
School attendance,
Number of snow plows in operation
Number of overdoses

2. 
Number of closed citizen complaints. Not good because it creates an incentive to close complaints rapidly rather than to make sure that they are actually solved.
Number of miles covered by street sweepers. Not good because it incentivizes covering ground rather than doubling back when something is missed to make sure it is actually cleaned.
Number of cars towed. Not clear if we want this metric to be high or low, depends on the context.

:::

## `streamlit` {style="font-size: 0.8em"}

We are teaching dashboards using `streamlit`. This is designed for data scientists who want to share analyses without needing front-end (e.g., web design) development skills. Beyond being easy to use, we chose to teach `streamlit` for a few reasons:

1. Native to Python, works well with existing Python tools (e.g. Altair)
1. All its features are free (so long as you are making public dashboards)
1. Open source: [https://github.com/streamlit/streamlit](https://github.com/streamlit/streamlit)

Caveat: `streamlit` is for prototyping (not computationally efficient for many users). We will talk more at the end of the lecture about how you will use streamlit and other tools going forward.

::: {.notes}

It is most useful for creating a prototype. If someone decides it is needs to be accessed by many users or needs to be built on top of secure data it will be replicated using a different dashboarding tool. This is very common. When professor Ganong worked at the city of Boston, everything that was going to be used on a continuing basis was transferred to another more stable platform. 

:::


## Citing our sources 
* These lecture slides draw on examples and text from [https://docs.streamlit.io](https://docs.streamlit.io).
* `streamlit` has fantastic documentation and [app gallery](https://streamlit.io/gallery)





## Introduction: summary

* Dashboards let non-coders interact with data
* Introduce `streamlit`
* Note on process: this is our first year teaching this lecture note so we are highly uncertain how long it will take (both each slide and the lecture overall)

::: {.notes}
Review table of contents for the rest of lecture
:::

# Dashboards as websites

## Prep 

* Create a separate repo just for your dashboards. Ours is [https://github.com/uchicago-harris-dap/dashboards](https://github.com/uchicago-harris-dap/dashboards)
* Be sure it is public.
* Save code; we will call this `1/hello_world_1.py`
```{python}
#| eval: false
import streamlit as st
st.write("""
# My first app
Hello *world!*
""")
```
* Push  code

::: {.notes}
Syntax notes 
* """...""" in Python creates a strong that can span multiple lines
* `#` defines header text -- like in QMD
* `*` defines italicized text 

:::

## My first dashboard 

In this lecture: `$` means run at the terminal (on Macs the prefix is `%`). You do not need to type `$`.

```{bash}
$ streamlit run 1/hello_world_1.py
```

* Recall: `Ctrl + C` to exit in Terminal 

::: {.notes}
We will start with the most simple possible dashboard. If you want to run this code, you can do just two steps first to install streamlit by running this first line of code at the terminal and then you run the script again at the command line. 

:::

## My first dashboard -- two ways to display
1. **Local** Create a server on your computer. Access from your web browser (and no one else's). Like we did on prior slide.
2. **Online** Create a server in the cloud. Access from any web browser.


## My first dashboard -- putting it online

* *(one time only)* connect your github account to streamlit community cloud. [(here)](https://streamlit.io/cloud)
* Three clicks: Deploy ->  Deploy Now (under Streamlit Community Cloud) -> Deploy (with pre-filled repo, branch, and file names).
* Now your app is online and can be shared via link: [http://uchicago-harris-dap-dashboards-1.streamlit.app/](http://uchicago-harris-dap-dashboards-1.streamlit.app/)
* Workflow: Streamlit does **not** actually deploy the script which is stored on your computer. Instead, it reads the script which is pushed to your public repo and deploys that.


::: {.notes}
Comment for maggie: You might wonder how it is possible that we will be live-deploying the same script multiple times (once every class). The answer is that each time we are just over-writing the existing deployment.

:::


## My second dashboard

* `$ streamlit run 2/hello_world_2_local.py` 
* Uncomment `st.altair_chart(chart_to_show)`. Save. Show detection of file change.
    * Fun fact: streamlit will automatically figure out how to print various data types to the web so you also can instead just write `chart_to_show`. 
* This is the normal workflow for building a streamlit dashboard. Update code. Save. Re-run locally. Once you are happy, then you deploy.
*  [http://uchicago-harris-dap-dashboards-2.streamlit.app/](http://uchicago-harris-dap-dashboards-2.streamlit.app/)

::: {.notes}
Next I will show slightly more sophisticated script (SCREEN: hello_world_2_local.py)

In this script, I‚Äôm going to need the Seattle weather file that you used earlier and visualization and then I‚Äôm going to make a chart out of it. 

Point to pandas command.

Point to altair command. 

SCREEN: Slide. Implement the steps described in the slide.

For the rest of this lecture, we aren't going to do any more live deployments (creates unnecessary live debugging) so instead just visit the deployed dashboard on the web.

SCREEN: [http://uchicago-harris-dap-dashboards-2.streamlit.app/](http://uchicago-harris-dap-dashboards-2.streamlit.app/). On that page,  review "manage app", "record a screencast"
:::



# Interactive dashboards

## Roadmap 

Dashboard 3. Multipage. 

Do-pair-share.

Dashboard 4. Uber pickups. "Classic" streamlit dashboard.


## Dashboard 3 roadmap 

1. Homepage with dropdown menu
1. Plotting demo with button
2. Dataframe demo with selection box and table
3. Mapping demo with checkboxes

Preview [http://uchicago-harris-dap-dashboards-3b.streamlit.app/](http://uchicago-harris-dap-dashboards-3b.streamlit.app/)

Going forward, we won't deploy locally anymore. But all the source code is located in the dashboards repo. For this one, you would deploy locally using `streamlit run 3/multipage.py`

## Dashboard 3 Homepage Review code {style="font-size: 0.8em"}
* Review structure of page and `intro()`
* *Lines 226-234*: created via `page_names_to_funcs` and `st.sidebar.selectbox(...)`

`3/multipage.py`: 
{{< include snippet/multipage.qmd >}}

::: {.notes}
* Have app up on on side and the code on the other.
* Scroll through and note that there are 4 functions -- intro(), mapping_demo(), plotting_demo(), and data_frame_demo(). 
* Walk through intro() function. Point to all the "st." methods and what they align with in the dashboard
* Scroll all the way down to where the dictionary page_names_to_funcs is defined. Point to the options in the dropdown menu.
    * keys: strings shown to user
    * values: function objects -- NOT function calls. intro as opposed to intro(), plotting_demo as opposed to plotting_demo(), etc.
    * `page_names_to_funcs[demo_name]()` is doing a "function dispatch via a dictionary". Basically, it says, look up which function corresponds to this select page name, and then run that function.

Equivalent to: 
```{python}
# | eval: false
if demo_name == "Plotting Demo":
    plotting_demo()
elif demo_name == "Mapping Demo":
    mapping_demo()
elif demo_name == "DataFrame Demo":
    data_frame_demo()
else:
    intro()
``` 

:::

## Feature: taking input
Streamlit has a huge number of different ways to take [input](https://docs.streamlit.io/develop/api-reference/widgets). In this lecture you will see:

* `st.button()`
* `st.checkbox()`
* `st.slider()`
* `st.selectbox()`

## Feature: layouts and containers
Streamlit also has many [layouts and containers](https://docs.streamlit.io/develop/api-reference/layout). In this lecture you will see:

* `st.sidebar()`
* `st.columns()`


## Feature: showing progress
Streamlit also has ways to show progress and failure [page](https://docs.streamlit.io/develop/api-reference/status). In this lecture you will see:

* `st.progress()`
* `st.error()`


## `plotting_demo()`  {style="font-size: 0.9em"}
* *Lines 6-13*: use `st.` commands to set up page
* *Lines 15-18*: set up blank `progress_bar`, `status_text`, `chart` in sidebar
* *Lines 20-28*: (usual python) loop to generate random numbers

{{< include snippet/1_üìà_Plotting_Demo.qmd >}}

::: {.notes}
In the static visualization lectures we mentioned vega-lite without explaining really how you would use it. Now you can see how it is used which is that Streamlit is going to write Vega-Lite for us 
:::

## DataFrame demo  data preview

```{python}
#| code-fold: true
import pandas as pd
def get_UN_data():
    AWS_BUCKET_URL = "http://streamlit-demo-data.s3-us-west-2.amazonaws.com"
    df = pd.read_csv(AWS_BUCKET_URL + "/agri.csv.gz")
    return df
```

```{python}
get_UN_data()
```

## DataFrame demo review code {style="font-size: 0.8em"}
* *Lines 25-27*: choose inputs `countries = st.multiselect()`
* *Line 36*: print table using `st.write()`
* *Line 41-43*: `pd.melt` in prepartion for `chart` 

`data_frame_demo()` from `3/multipage.py`: 
{{< include snippet/3_üìä_DataFrame_Demo.qmd >}}

## Feature: showing output

_for text_

`st.markdown()`

_for anything_

`st.write()`

*  In this example, `st.write()` is used to make a table (analogous to `print()` or `head()`)
* Useful tip: `st.write()` is Streamlit's "Swiss Army knife". Pass almost anything: latex, Matplotlib figures, Altair charts, multiple arguments, and more. Don't worry, Streamlit will figure it out and render things the right way. Full list [here](https://docs.streamlit.io/develop/api-reference/write-magic/st.write)




## Mapping demo data preview {style="font-size: 0.8em"}

* Runs on [`pydeck`](https://deckgl.readthedocs.io/en/latest/) ("High-scale spatial rendering"). 
* Makes gorgeous maps (will have more depth in minilesson). 
* In Terminal/command line: update conda environment or `$ pip install pydeck`

| data preview  | 
| --- | 
| [bike_rental_stats](http://raw.githubusercontent.com/streamlit/example-data/master/hello/v1/bike_rental_stats.json) | 
|  [bart_stop_stats](http://raw.githubusercontent.com/streamlit/example-data/master/hello/v1/bart_stop_stats.json)|
| [bart_path_stats](http://raw.githubusercontent.com/streamlit/example-data/master/hello/v1/bart_path_stats.json) | 


## mapping demo review code

Review `HexagonLayer`, `ScatterplotLayer`, `TextLayer`, `ArcLayer`

`mapping_demo()` from `3/multipage.py`: 
{{< include snippet/2_üåç_Mapping_Demo.qmd >}}

## (Optional) Summarize how each dataset is used {style="font-size: 0.8em"}

|  Data preview  | Layer name | notes |
| --- | --- | --- |
| [bike_rental_stats](http://raw.githubusercontent.com/streamlit/example-data/master/hello/v1/bike_rental_stats.json) | `HexagonLayer`  |  bar height set by number of rentals at each lat lon |
| [bart_stop_stats](http://raw.githubusercontent.com/streamlit/example-data/master/hello/v1/bart_stop_stats.json) | `ScatterplotLayer` | radius = `exits`|
| [bart_stop_stats](http://raw.githubusercontent.com/streamlit/example-data/master/hello/v1/bart_stop_stats.json) | `TextLayer`   | `get_text="name"` |
| [bart_path_stats](http://raw.githubusercontent.com/streamlit/example-data/master/hello/v1/bart_path_stats.json) | `ArcLayer` |  arcs via `get_source_position = ["lon", "lat"], get_target_position = ["lon2", "lat2"]` |


::: {.notes}
Not sure we will need to talk about this. only cover it if people are confused from looking at the code itself.
:::


## Control flow: what code exactly does streamlit run?

Streamlit tries to run your code like a normal python script.

If you write a function and never call it, it is not run. To understand what's run here, the key code block is this

```{.python}
page_names_to_funcs = {
    "‚Äî": intro,
    "Plotting Demo": plotting_demo,
    "Mapping Demo": mapping_demo,
    "DataFrame Demo": data_frame_demo
}

demo_name = st.sidebar.selectbox("Choose a demo", page_names_to_funcs.keys())
page_names_to_funcs[demo_name]()
```

## do-pair-share {background-color="aliceblue"}

1. Render dashboard code in student repo (`student30538-w26/lectures/dashboard/app_dps_1.py`) at the command line/Terminal: `$ streamlit run app_dps_1.py`
2. Edit `.py` so that user can select multiple items instead of just one: display Bus routes, L routes, or both in sidebar
3. Re-render

*Hint: browse through documentation for [input options](https://docs.streamlit.io/develop/api-reference/widgets) *

## Uber pickups: a full-fledged dashboard 


[http://uchicago-harris-dap-dashboards-4.streamlit.app/](http://uchicago-harris-dap-dashboards-4.streamlit.app/)

* This is the "classic" Streamlit dashboard (the one they use in all the demos) 
* Why? Pretty, adapts nicely to user input, and it showcases integration with `pydeck` and `altair`.

## Uber pickups: preview data
```{python}
#| code-fold: true
import os
def load_data():
    path = "uber-raw-data-sep14.csv.gz"
    if not os.path.isfile(path):
        path = f"https://github.com/streamlit/demo-uber-nyc-pickups/raw/main/{path}"

    data = pd.read_csv(
        path,
        nrows=6,  
        names=[
            "date/time",
            "lat",
            "lon",
        ],  # specify names directly since they don't change
        skiprows=1,  # don't read header since names specified directly
        usecols=[0, 1, 2],  # doesn't load last column, constant value "B02512"
        parse_dates=[
            "date/time"
        ],  # set as datetime instead of converting after the fact
    )

    return data
```

```{python}
load_data()
```

## Uber pickups review code {style="font-size: 0.7em"}
* *Lines 115-19*: user chooses time of day (`pickup_hour`)
* *Lines 69-70*: helper function `filterdata(data, hour_selected)` 
* *Lines 41, 140-157*: `map(data, lat, lon, zoom)` makes a PyDeck `HexagonLayer`. Repeat 4x.
* *Lines 170-182*: `histdata(df, hr)` makes an altair histogram with n rides

`4/uber_pickups.py`: 
{{< include snippet/uber_pickups.qmd >}}

::: {.notes}
Discussion question -- Why does `map` need to take lat and lon as an argument?
Answer: this is saying where we should be looking when the map is first created

Show that if you zoom out on the three airports you get back to the exact same underlying dataset, it's just starting in a different place.

:::

## Summary

Saw four dashboards

* Multipage
    * plot
    * data frame
    * map
* Uber pickups -- map + plot

# Demystifying dashboards


## Roadmap
* Why dashboards are different than `.py` (or notebooks or `qmd`)
* Bare vs streamlit mode
* toy example of what streamlit mode can do
* What is a session?


## Why dashboards are different than `.py` {style="font-size: 0.8em"}

The first section of this lecture treated dashboards as websites without user input. This is like a normal Python script. Run once and gives you output.

The second section made dashboards interactive. To do this, it must be the case that the entire dashboard, or some part of it, may be run more than once.

- In Terminal/command line: `$ pip install watchdog`

`watchdog` is the file-watching library Streamlit leans on to detect code/data changes (like when we got the option to "re-run" with dashboard 2)

## Bare mode vs streamlit mode {style="font-size: 0.8em"}

* "Bare mode" (`$ python app.py`) runs your script like standard Python; output is just whatever the script prints. 
* "Streamlit mode" (`$ python -m streamlit run app.py` or for short `$ streamlit run app.py`) does four things:
    * sets up a server to run your script
    * records the state (e.g. the choice in `st.selectbox`)
    * reruns code on state changes (e.g. new choice in in `st.selectbox`)
    * serves the interactive user interface (UI) found in the browser
* There's a lot of extra code under the hood, streamlit's goal is for you to focus on the Python code (and ignore all the running a server, taking user input, designing a nice webpage)


## Simple re-run demo overview {style="font-size: 0.8em"}

[http://uchicago-harris-dap-dashboards-5.streamlit.app/](http://uchicago-harris-dap-dashboards-5.streamlit.app/)

* `$ streamlit run 5/session_state_example.py`
* User chooses `route = st.selectbox("CTA Route", ...)` and `cut_pct = st.slider("What fraction of service to cut?", ...)`
* Computer then runs a computation which takes 3 seconds (on the pset, you will see an example where it takes much longer than 3 seconds)
* Returns a result
* What if we want to run the exact same computation twice? Better to use the saved result!

## Simple re-run demo review code
* Users selects line to cut and percentage cut -- lines 11 and 12
* Record number of calculations done and key for calculations done -- lines 14-18
* If calculation has not been run before, run it -- lines 21-25

{{< include snippet/session_state_example.qmd >}}

## What is a session? {style="font-size: 0.8em"}

* A session is a single instance of viewing an app. 
* Multiple users = multiple sessions. 
* If the user refreshes their browser page or reloads the URL to the app, their Session State resets and they begin again with a new session.
* Session State provides a dictionary-like interface where you can preserve info between script reruns. Use `st.session_state` with key or attribute notation to store and recall values. For example, `st.session_state.my_key`. 

## summary

* dashboards expect to be run more than once
* bare mode lets you test running just once
* when you run slow code, save the output
* each browser tab is a session


# decorators and `@cache_data`

## roadmap

* decorator examples
    * timer 
    * crs for spatial joins
    * `@cache_data`
* revisit toy example from last section
* real-life example


## Timing pandas data processing

```{python}
import pandas as pd, time

def timer(func):
    """Decorator that prints runtime."""
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} took {end - start:.3f} s")
        return result
    return wrapper

@timer
def summarize(df):
    return df.groupby("city")["value"].mean()

df = pd.DataFrame({"city": ["SF","NYC","LA","Chicago"]*3, "value": range(12)})
summary = summarize(df)
summary
```

## Ensure CRS for GeoPandas joins

```{python}
#| eval: false
import geopandas as gpd

def ensure_crs(crs):
    """Ensure GeoDataFrames use the same CRS."""
    def decorator(func): #unlike prior example, this decorator takes an arg
        def wrapper(gdf1, gdf2, *args, **kwargs):
            if gdf1.crs != crs:
                gdf1 = gdf1.to_crs(crs)
            if gdf2.crs != crs:
                gdf2 = gdf2.to_crs(crs)
            return func(gdf1, gdf2, *args, **kwargs)
        return wrapper
    return decorator

@ensure_crs("EPSG:4326") #center at 0 lat 0 lon
def spatial_join(gdf1, gdf2):
    return gpd.sjoin(gdf1, gdf2, how="inner")
```


## Automate toy example via cache-ing
```{python}
#| eval: false
@st.cache_data
def long_running_function(param1, param2):
    return ‚Ä¶
```

1. When user first calls `long_running_function(p1, p2)` for the first time, `@st.cache_data` makes a note of `p1, p2`. It stores the return value in a cache.
2. If the next call is `long_running_function(q1, q2)`, it also stores this in the cache.
3. (time-saving) If the next call is `long_running_function(p1, p2)`, instead of running any code, it just returns the saved value from the cache.


## do-pair-share {background-color="aliceblue"}

1. Run `$ python app_dps_2.py`
2. Edit the script to include a decorator that saves output from prior runs of `compute_passengers()`
3. Record the change in speed

## cache data in streamlit

{{< include snippet/session_state_cache.qmd >}}

[http://uchicago-harris-dap-dashboards-6.streamlit.app/](http://uchicago-harris-dap-dashboards-6.streamlit.app/)

## Revisit a real example: `4/uber_pickups.py`

We have decorated `@st.cache_data` for four different functions

1. `load_data()` 
2. `filterdata(data, hour_selected)`
3. `mpoint()`
4. `histdata()`


## Summary: What all decorators have in common {style="font-size: 0.8em"}

* All wrap a function with extra behavior. 
* They take a function as input and return a modified version.
* Create them when you know you will use an **already-written** function more than once
* Syntax: `@decorator` above a function definition.
* Examples
    * Timing and logging (`@timer`)
	* Validation or transformation (`@ensure_crs(crs)`)
	* Caching (`@st.cache_data`)
* Remark: Decorators are not a dashboard-only tool! We can write our own decorators, or use ones that come with a package (st.cache_data is the latter).

# Streamlit and other types of dashboards {style="font-size: 0.8em"}

## Roadmap

* Tips for streamlit
* Tips for final project
* Streamlit vs other dashboarding software
* Promise and pitfalls of dashboards revisited

## Streamlit Tips 
* Lay out your editor and browser windows side by side, so the code and the app can be seen at the same time.
* Your main script should live in a directory other than the root directory.
* [https://docs.streamlit.io/develop/quick-reference/cheat-sheet](https://docs.streamlit.io/develop/quick-reference/cheat-sheet)

## Other Streamlit applications we will not cover (examples on the streamlit website)
* Chat box / LLM wrapper
* Draw on external data (user uploaded, from a live database, etc.)

## How should you use streamlit for the final project (and in life)? 
* Build a dashboard when a static figure or table will not suffice
* This occurs when there is too much information to fit on a single figure or table (e.g. one dashboard is better than ten figures)
* The goal, however, is not to proliferate information (e.g. "how can I imagine ten figures so that then I can shoehorn them into dashboard?"). 
* Instead, it is to develop a set of information that a reader or decision-maker would want to interact with.

## Streamlit and other dashboarding tools {style="font-size: 0.8em"}

Streamlit is not in the top 10 of most commonly-used dashboards.

What software might you see elsewhere? Microsoft Power BI, tableau, Qlik, Looker, SAP, plotly, shiny

What dashboard should you use? This is not an important choice. Use whatever your organization or collaborators are already using. Or prototype in streamlit and then port.

What if a job you apply for requires a specific dashboarding software? Spend a few hours teaching it to yourself and then put it on your resume (do **not** just put it on your resume). Or put dashbaords in general and learn the skill for the interview.

## The most famous dashboard ever  {style="font-size: 0.8em"}
New York City Police Department's "CompStat" in the 1990's. Why is it such a perfect application of a dashboard? (Source: *Classic book: Bob Behn's [The PerformanceStat Potential](https://www.brookings.edu/books/the-performancestat-potential/)*)

<!-- note to self: I skipped 4 and 7 since I didn't think they make a lot of sense-->
1. Metrics (arrests, crime rate) are clearly aligned with institutional goals
2. Data are automatically collected daily
3. Historical baseline data are available
4. Focused efforts can produce immediate results
5. All police commanders start as beat cops
6. Multiple subunits facilitate comparison
7. Size plus managerial discretion creates personnel flexibility

Very few other parts of government can meet all seven of these criteria

## Skeptic

Even under these perfect conditions, the dashboard was not very successful. In a survey of 1800 retired NYC police officers of the question ‚Äúare you confident that major crimes have declined by 80% in New York since 1990s?‚Äù more than half said no (Eterno, Verma, and Silverman 2014). Respondents also talked about pressure to change reports to make crime look better.

The key idea is that "what gets measured gets managed". Once a manger focuses on a metric, that metric becomes less useful or informative than it was before.


## Conclusion of section

* Streamlit is an amazing tool
* The key skill, however, is not streamlit, it is organizing information for an external analyst or decision-maker.
* Dashboards have real downsides
* In spite of these downsides, dashboards continue to grow in popularity



# Backup slides
## Backup: Altair troubleshooting 

* It is possible to have Altair installed (as captured by `pip show altair`) but also have `import altair` fail on mac with a chip architecture error: `have 'x86_64', need 'arm64e' or 'arm64')`
* Didn't work: make a new `venv` or update Python. 
* Worked: `pip install --force-reinstall --no-cache-dir --only-binary=:all: rpds-py`

## Backup: Altair troubleshooting

‚ÄúThis is a compatibility issue between the package's [altair‚Äôs] generated schema and Python 3.14.‚Äù 

Solution: downgrade to Python 3.12.


## Backup: Streamlit troubleshooting 
Make sure that your virtual environment is active!

urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>

Solution Find your Python‚Äôs ‚ÄúInstall Certificates.command‚Äù in Finder:
1. Open¬†/Applications.
2. Enter the folder for your Python (for example¬†Python 3.11).
3. Double-click¬†Install Certificates.command.